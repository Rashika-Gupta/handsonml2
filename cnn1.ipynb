{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3oue9SVNe1UIm3mrIwMmC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rashika-Gupta/handsonml2/blob/main/cnn1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XEuPBiYMxP54"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = './'\n",
        "transform = transforms.Compose([transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "Nt8uTFEBzcJ1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_dataset = torchvision.datasets.MNIST(root=image_path,\n",
        "                                           train=True,\n",
        "                                           transform=transform,\n",
        "                                           download=True)\n"
      ],
      "metadata": {
        "id": "s-MmitE6zp-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc4fbc70-4bdc-4227-ab46-2fb4a2e7a642"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 99843929.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 25321006.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 39990813.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 1110170.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import mnist\n",
        "#creating the dataset into valid and training ds\n",
        "from torch.utils.data import Subset\n",
        "mnist_valid_dataset = Subset(mnist_dataset, torch.arange(10000))\n",
        "mnist_train_dataset = Subset(mnist_dataset, torch.arange(10000, len(mnist_dataset)))\n",
        "\n",
        "#getting the test dataset\n",
        "mnist_dataset = torchvision.datasets.MNIST(root=image_path,\n",
        "                                           train=False,\n",
        "                                           transform=transform,\n",
        "                                           download=False)\n"
      ],
      "metadata": {
        "id": "WvwNnYbZzsH6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mnist_train_dataset.shape"
      ],
      "metadata": {
        "id": "vtslcsYZckx9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 64\n",
        "torch.manual_seed(1)\n",
        "train_dl = DataLoader(mnist_train_dataset, batch_size, shuffle = True)\n",
        "valid_dl = DataLoader(mnist_valid_dataset, batch_size, shuffle = True)\n"
      ],
      "metadata": {
        "id": "GXmEkpOp0cfJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential() #stacking different layers - convolution, pooling, drop-out\n",
        "model.add_module(\n",
        "    'conv1', nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 5, padding= 2), #defingin kernel_Size = 5*5, first convolution has 32 output features (32 filters )\n",
        "      )\n",
        "model.add_module('relu1', nn.ReLU())\n",
        "model.add_module('pool1', nn.MaxPool2d(kernel_size=2))\n",
        "model.add_module('conv2', nn.Conv2d(in_channels= 32, out_channels= 64, kernel_size= 5, padding = 2))\n",
        "model.add_module('relu2', nn.ReLU())\n",
        "model.add_module('pool2', nn.MaxPool2d(kernel_size=2))"
      ],
      "metadata": {
        "id": "CSFaESlG1CDp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pytorch takes input as the form of NCHW ( # of images in a batch, C for channels, H heigh, W width)"
      ],
      "metadata": {
        "id": "bYmVg8wuc4pL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones((4,1,28,28))\n",
        "model(x) # passing atuple where there are 4 images per batch, 1 cannel (i.e) 2 d image or on gray scale and 28*28 is the pixel length\n",
        "model(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlKIMD4Z7WpH",
        "outputId": "896085a2-5cac-4865-c2f9-5aa7b04b82a1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 64, 7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the shape taht we got is because the output llayer is 64 (i.e - 64 kernels in the end or 64 filter/feature extraction, 28 reduced to 7 because there is pooling applied twice which has  reducd by 4)"
      ],
      "metadata": {
        "id": "VTK_MwQfdjx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to feed in the deep nn\n",
        "#flatten it\n",
        "model.add_module('fc1', nn.Linear(3136, 1024))\n",
        "model.add_module('relu3', nn.ReLU())\n",
        "model.add_module('dropout', nn.Dropout(p = 0.5))\n",
        "model.add_module('fc2', nn.Linear(1024, 10))"
      ],
      "metadata": {
        "id": "kVvsuAId7cz6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defning the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
      ],
      "metadata": {
        "id": "RQFq2jjnepT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define the training function\n",
        "def train (model, num_epochs, train_dl, valid_dl):\n",
        "  loss_hist_train = [0]*num_epochs\n",
        "  accuracy_hist_train =[0]*num_epochs\n",
        "  loss_hist_train = [0]*num_epochs\n",
        "  accuracy_hist_train =[0]*num_epochs\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for x_batch, y_batch in train_dl:\n",
        "      pred = model(x_batch)\n",
        "      loss = loss_fn(pred, y_batch)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      loss_hist_train[epoch] += loss.item()*y_batch.size(0)\n",
        "\n",
        "      is_correct = ( torch.argmax(pred, dim = 1) == y_batch).float()\n",
        "      accuracy_hist_train[epoch] += is_correct.sum()\n",
        "\n",
        "    loss_hist_train[epoch] /= len(train_dl.dataset)\n",
        "    accuracy_hist_train[epoch] /= len(train_dl.dataset)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bZ6aHHmFe11e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}